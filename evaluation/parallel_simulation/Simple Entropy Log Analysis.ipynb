{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ***Be sure to source setup.bash before launching jupyter server***\n",
    "%matplotlib inline\n",
    "\n",
    "import rospy\n",
    "import rosbag\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import tf_conversions\n",
    "import scipy.stats as st\n",
    "\n",
    "from matplotlib.patches import Ellipse\n",
    "\n",
    "from custom_messages.msg import SimulationDataMsg\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/home/joshua/Documents/Uni/Year4/dissertation/catkin_ws/src/linefollow_gazebo/scripts/\")\n",
    "import CameraNetwork\n",
    "import Path \n",
    "import RoadModel\n",
    "import Tracer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_to_numpy(point):\n",
    "    return np.array([point.x, point.y, point.z])\n",
    "def vec_to_numpy(vec):\n",
    "    return point_to_numpy(vec)\n",
    "def quat_to_numpy(quat):\n",
    "    return np.array([quat.x, quat.y, quat.z, quat.w])\n",
    "def quat_to_rpy(quat):\n",
    "    # note: need numpy quaternion\n",
    "    return tf_conversions.transformations.euler_from_quaternion(quat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_defs_root = \"defs\"\n",
    "experiment_gen_root = \"gen\"\n",
    "specific_experiment_paths = [['calibration_circuit.json'], ['calibration_circuit_mirror.json']] # subbpath to only process 1 experiment dir or .json, not all at once\n",
    "# specific_experiment_paths = [['straight_road_80m_centercam_pos3.json']]\n",
    "if len(specific_experiment_paths) > 0:\n",
    "    specific_experiments = [os.path.join(*p) for p in  specific_experiment_paths]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bagfiles_for(experiment_path):\n",
    "    if not experiment_path[-1].endswith('.json'):\n",
    "        print(\"must provide .json file\")\n",
    "    gen_path = 'gen'\n",
    "    if len(experiment_path) > 0:\n",
    "        if len(experiment_path) > 1:\n",
    "            gen_path = os.path.join(gen_path, os.path.join(*experiment_path[:-1]))\n",
    "        exp_name = experiment_path[-1].split('.')[-2]\n",
    "        gen_path = os.path.join(gen_path, exp_name)\n",
    "    if os.path.isdir(gen_path):\n",
    "        # collect all .bag files!\n",
    "        bag_files = []\n",
    "        for path, dirs, files in os.walk(gen_path):\n",
    "            for f in files:\n",
    "                if f.endswith('.bag'):\n",
    "                    bag_file_path = os.path.join(path, f)\n",
    "                    bag_files.append(bag_file_path)\n",
    "        return bag_files\n",
    "    else:\n",
    "        print(\"{0} is not generated!\".format(gen_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bagfiles_for_set(experiment_path):\n",
    "    # assume pass in a directory containing many .json files\n",
    "    files = os.listdir(os.path.join(*experiment_path))\n",
    "    \n",
    "    bagfiles = []\n",
    "    def_files = []\n",
    "    for def_file in files:\n",
    "        if not def_file.endswith('.json'):\n",
    "            print(\"skipping: {0}\".format(def_file))\n",
    "            continue\n",
    "        path = experiment_path + [def_file]\n",
    "        def_files.append(path)\n",
    "        bagfiles.append(get_bagfiles_for(path))\n",
    "    \n",
    "    \n",
    "    return def_files, bagfiles\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gen/calibration_circuit/runner_0/run_0/sim_data.bag',\n",
       " 'gen/calibration_circuit/runner_0/run_1/sim_data.bag',\n",
       " 'gen/calibration_circuit/runner_1/run_2/sim_data.bag',\n",
       " 'gen/calibration_circuit/runner_1/run_0/sim_data.bag',\n",
       " 'gen/calibration_circuit/runner_1/run_1/sim_data.bag']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_step_entropies(bag, max_steps):\n",
    "    total_entropy = 0\n",
    "    for i, msg in enumerate(bag):\n",
    "        if i >= max_steps:\n",
    "            break\n",
    "        msg = msg.message\n",
    "        ekf_cov = np.array(msg.ekf_odom.pose.covariance).reshape(6,6)[:3, :3]\n",
    "        # have covariance truncated to x, y, theta only\n",
    "        \n",
    "        # diff. entropy = H(xt | z1:t, u1:t)\n",
    "        differential_entropy = np.log(np.sqrt((2*np.pi*np.e)**(3) * np.linalg.det(ekf_cov)))\n",
    "        \n",
    "        total_entropy += differential_entropy\n",
    "    \n",
    "    return total_entropy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean_summed_entropy(bagfiles, max_steps):\n",
    "    total, n = 0.0, 0\n",
    "    for f in bagfiles:\n",
    "        bag = rosbag.Bag(f)\n",
    "        total += sum_step_entropies(bag, max_steps)\n",
    "        n += 1\n",
    "    \n",
    "    return total/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_min_num_in_files(bagfiles):\n",
    "    min_n = 9999999\n",
    "    for f in bagfiles:\n",
    "        bag = rosbag.Bag(f)\n",
    "        num_msgs = bag.get_message_count()\n",
    "        if num_msgs < min_n:\n",
    "            min_n = num_msgs\n",
    "    return min_n\n",
    "\n",
    "def get_min_number_of_steps(set_of_bagfiles):\n",
    "    \"\"\" Takes list of lists of bagfiles, finds the minimum steps taken\"\"\"\n",
    "    min_steps = 99999999\n",
    "    for files in set_of_bagfiles:\n",
    "        m = get_min_num_in_files(files)\n",
    "        if m < min_steps:\n",
    "            min_steps = m\n",
    "    return min_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean summed entropy from covariance matrices: -1029.5184933\n",
      "141\n"
     ]
    }
   ],
   "source": [
    "# for one example for now, wrap in function later\n",
    "files = get_bagfiles_for(['straight_road_80m_centercam_pos3.json'])\n",
    "# max_steps = get_min_number_of_steps([files])\n",
    "max_steps = 141\n",
    "print(\"Mean summed entropy from covariance matrices: {0}\".format(calculate_mean_summed_entropy(files, max_steps)))\n",
    "print(max_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean summed entropy from covariance matrices: -1010.33328212\n",
      "141\n"
     ]
    }
   ],
   "source": [
    "# for one example for now, wrap in function later\n",
    "files = get_bagfiles_for(['straight_road_80m_centercam_pos2.json'])\n",
    "max_steps = get_min_number_of_steps([files])\n",
    "print(\"Mean summed entropy from covariance matrices: {0}\".format(calculate_mean_summed_entropy(files, max_steps)))\n",
    "print(max_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean summed entropy from covariance matrices: -953.132931825\n",
      "141\n"
     ]
    }
   ],
   "source": [
    "# for one example for now, wrap in function later\n",
    "files = get_bagfiles_for(['straight_road_80m_centercam_pos1.json'])\n",
    "max_steps = get_min_number_of_steps([files])\n",
    "max_steps=141\n",
    "print(\"Mean summed entropy from covariance matrices: {0}\".format(calculate_mean_summed_entropy(files, max_steps)))\n",
    "print(max_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
